# utcp-mcp-gateway

<p align="center">
  <strong>ğŸš€ The Smarter Way to Use MCP â€” Save 90%+ Tokens with Code Mode</strong>
</p>

<p align="center">
  <a href="#english">English</a> | <a href="#ä¸­æ–‡">ä¸­æ–‡</a>
</p>

<p align="center">
  <em>Endorsed by Apple, Cloudflare, and Anthropic</em>
</p>

---

<a name="english"></a>

## What is this?

**LLMs are great at writing code, but terrible at tool calling.**

Traditional MCP exposes tools directly to LLMs â€” but LLMs struggle with:
- Too many tools (500+ definitions = confusion)
- Huge responses (10,000+ chars = wasted tokens)  
- Multiple round trips (15+ API calls = slow & expensive)

**`utcp-mcp-gateway` fixes all of this:**

| Problem | Solution |
|---------|----------|
| 500+ tool definitions | **Progressive Discovery** â€” load only what's needed |
| 10,000+ char responses | **LLM Filtering** â€” smart summarization (97% smaller!) |
| 15+ API round trips | **Code Mode** â€” one code block, one execution |

```
Traditional:  User â†’ LLM â†’ Tool1 â†’ LLM â†’ Tool2 â†’ LLM â†’ Tool3 â†’ Result
              (15+ calls, $26/day, slow)

Code Mode:    User â†’ LLM writes code â†’ Execute all at once â†’ Result  
              (1 call, $0.87/day, fast)
```

**Result: $9,536/year savings** ([benchmark source](https://github.com/imran31415/codemode_python_benchmark))

## Quick Start

**Zero config files needed!** Just add to Claude Desktop config:

### Mode 1: HTTP MCP (Remote)

```json
{
  "mcpServers": {
    "gateway": {
      "command": "npx",
      "args": ["-y", "utcp-mcp-gateway"],
      "env": {
        "MCP_URL": "https://mcp.context7.com/mcp",
        "MCP_NAME": "context7",
        "LLM_API_KEY": "sk-xxx",
        "LLM_BASE_URL": "https://api.openai.com/v1",
        "LLM_MODEL": "gpt-4o-mini"
      }
    }
  }
}
```

### Mode 2: stdio MCP (Local)

```json
{
  "mcpServers": {
    "gateway": {
      "command": "npx",
      "args": ["-y", "utcp-mcp-gateway"],
      "env": {
        "MCP_COMMAND": "npx",
        "MCP_ARGS": "-y,@anthropic/mcp-server-filesystem",
        "MCP_NAME": "filesystem",
        "MCP_TRANSPORT": "stdio",
        "LLM_API_KEY": "sk-xxx"
      }
    }
  }
}
```

> âš ï¸ **Windows Users:** Use `cmd /c npx` instead of `npx`:
> ```json
> "command": "cmd",
> "args": ["/c", "npx", "-y", "utcp-mcp-gateway"]
> ```

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `MCP_URL` | HTTP mode | MCP server URL |
| `MCP_COMMAND` | stdio mode | Command to run MCP |
| `MCP_ARGS` | stdio mode | Arguments (comma-separated) |
| `MCP_NAME` | âœ… | MCP namespace |
| `MCP_TRANSPORT` | No | `http` (default) or `stdio` |
| `LLM_API_KEY` | For filtering | Any OpenAI-compatible API key |
| `LLM_BASE_URL` | For filtering | API endpoint (default: OpenAI) |
| `LLM_MODEL` | For filtering | Model name (default: gpt-4o-mini) |

That's it! Restart Claude Desktop and try: *"Search for React useState examples"*

## Features

| Feature | Description |
|---------|-------------|
| ğŸ”Œ **Universal MCP** | Connect any HTTP or stdio MCP server |
| ğŸ§  **LLM Filtering** | Intelligent summarization (97% response reduction!) |
| ğŸ” **Progressive Discovery** | `search_tools` - find tools without loading all 500 definitions |
| âš¡ **Code Mode** | Execute TypeScript tool chains in one call |
| ğŸ”’ **Secure Sandbox** | Code runs in isolated environment |
| ğŸ“¦ **Zero Config** | Environment variables only, no config files |

## Token Savings Benchmarks

| MCP Service | Original | Filtered | Savings |
|-------------|----------|----------|---------|
| Context7 (docs) | 10,625 chars | 326 chars | **97%** |
| DeepWiki (wiki) | 3,318 chars | 400 chars | **88%** |

## Configuration

### Single MCP

```bash
MCP_URL=https://mcp.context7.com/mcp
MCP_NAME=context7
```

### Multiple MCPs

```bash
MCP_URLS=https://mcp.context7.com/mcp,https://mcp.deepwiki.com/mcp
MCP_NAMES=context7,deepwiki
```

### LLM Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `LLM_API_KEY` | - | OpenAI/OpenRouter API key |
| `LLM_BASE_URL` | OpenAI | Custom endpoint (OpenAI-compatible) |
| `LLM_MODEL` | gpt-4o-mini | Model for summarization |
| `ENABLE_LLM_FILTER` | true | Enable/disable filtering |
| `MAX_RESPONSE_CHARS` | 2000 | Max response length |

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your AI    â”‚â”€â”€â”€â”€â–¶â”‚      utcp-mcp-gateway           â”‚â”€â”€â”€â”€â–¶â”‚ Any MCP     â”‚
â”‚ (Claude etc) â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚ (Context7)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  UTCP   â”‚  â”‚ LLM Filter  â”‚   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  â”‚ search  â”‚  â”‚ 10Kâ†’300char â”‚   â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gateway exposes 4 tools to your AI:**

| Tool | Parameters | What it does |
|------|------------|--------------|
| `search_tools` | `query`, `limit` | Find tools by keyword. Returns only relevant tools instead of 500+ definitions |
| `list_tools` | - | List all registered tools from connected MCPs |
| `call_tool` | `tool_name`, `arguments` | Call any tool. Response is filtered by LLM (97% smaller!) |
| `call_tool_chain` | `code` | Execute TypeScript code that calls multiple tools in one shot |

### Example Flow

```
User: "How do I use React useState?"

1. AI calls search_tools("react")        â†’ Returns 2 relevant tools
2. AI calls call_tool("get-library-docs", {topic: "useState"})
3. Gateway fetches 10,000 chars from Context7
4. LLM Filter summarizes to 300 chars    â†’ 97% token saved!
5. AI receives concise answer
```

---

<a name="ä¸­æ–‡"></a>

## è¿™æ˜¯ä»€ä¹ˆï¼Ÿ

**LLM æ“…é•¿å†™ä»£ç ï¼Œä½†ä¸æ“…é•¿è°ƒç”¨å·¥å…·ã€‚**

ä¼ ç»Ÿ MCP ç›´æ¥æŠŠå·¥å…·æš´éœ²ç»™ LLM â€” ä½† LLM é¢ä¸´ï¼š
- å·¥å…·å¤ªå¤šï¼ˆ500+ å®šä¹‰ = å›°æƒ‘ï¼‰
- å“åº”å¤ªå¤§ï¼ˆ10,000+ å­—ç¬¦ = æµªè´¹ Tokenï¼‰
- å¾€è¿”å¤ªå¤šï¼ˆ15+ æ¬¡ API è°ƒç”¨ = æ…¢ä¸”è´µï¼‰

**`utcp-mcp-gateway` ä¸€æ¬¡è§£å†³æ‰€æœ‰é—®é¢˜ï¼š**

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| 500+ å·¥å…·å®šä¹‰ | **æ¸è¿›å¼å‘ç°** â€” åªåŠ è½½éœ€è¦çš„ |
| 10,000+ å­—ç¬¦å“åº” | **LLM è¿‡æ»¤** â€” æ™ºèƒ½æ‘˜è¦ï¼ˆç¼©å° 97%ï¼ï¼‰|
| 15+ æ¬¡ API å¾€è¿” | **Code Mode** â€” ä¸€æ®µä»£ç ï¼Œä¸€æ¬¡æ‰§è¡Œ |

```
ä¼ ç»Ÿæ–¹å¼:   ç”¨æˆ· â†’ LLM â†’ å·¥å…·1 â†’ LLM â†’ å·¥å…·2 â†’ LLM â†’ å·¥å…·3 â†’ ç»“æœ
            (15+ æ¬¡è°ƒç”¨, $26/å¤©, æ…¢)

Code Mode:  ç”¨æˆ· â†’ LLM å†™ä»£ç  â†’ ä¸€æ¬¡æ‰§è¡Œå…¨éƒ¨ â†’ ç»“æœ
            (1 æ¬¡è°ƒç”¨, $0.87/å¤©, å¿«)
```

**ç»“æœï¼šæ¯å¹´èŠ‚çœ $9,536** ([åŸºå‡†æµ‹è¯•æ¥æº](https://github.com/imran31415/codemode_python_benchmark))

## å¿«é€Ÿå¼€å§‹

**é›¶é…ç½®æ–‡ä»¶ï¼** ç›´æ¥æ·»åŠ åˆ° Claude Desktop é…ç½®ï¼š

### æ¨¡å¼ 1ï¼šHTTP MCPï¼ˆè¿œç¨‹ï¼‰

```json
{
  "mcpServers": {
    "gateway": {
      "command": "npx",
      "args": ["-y", "utcp-mcp-gateway"],
      "env": {
        "MCP_URL": "https://mcp.context7.com/mcp",
        "MCP_NAME": "context7",
        "LLM_API_KEY": "sk-xxx",
        "LLM_BASE_URL": "https://api.openai.com/v1",
        "LLM_MODEL": "gpt-4o-mini"
      }
    }
  }
}
```

### æ¨¡å¼ 2ï¼šstdio MCPï¼ˆæœ¬åœ°ï¼‰

```json
{
  "mcpServers": {
    "gateway": {
      "command": "npx",
      "args": ["-y", "utcp-mcp-gateway"],
      "env": {
        "MCP_COMMAND": "npx",
        "MCP_ARGS": "-y,@anthropic/mcp-server-filesystem",
        "MCP_NAME": "filesystem",
        "MCP_TRANSPORT": "stdio",
        "LLM_API_KEY": "sk-xxx"
      }
    }
  }
}
```

> âš ï¸ **Windows ç”¨æˆ·ï¼š** ä½¿ç”¨ `cmd /c npx` ä»£æ›¿ `npx`ï¼š
> ```json
> "command": "cmd",
> "args": ["/c", "npx", "-y", "utcp-mcp-gateway"]
> ```

### ç¯å¢ƒå˜é‡

| å˜é‡ | å¿…å¡« | è¯´æ˜ |
|------|------|------|
| `MCP_URL` | HTTP æ¨¡å¼ | MCP æœåŠ¡å™¨ URL |
| `MCP_COMMAND` | stdio æ¨¡å¼ | è¿è¡Œ MCP çš„å‘½ä»¤ |
| `MCP_ARGS` | stdio æ¨¡å¼ | å‚æ•°ï¼ˆé€—å·åˆ†éš”ï¼‰|
| `MCP_NAME` | âœ… | MCP å‘½åç©ºé—´ |
| `MCP_TRANSPORT` | å¦ | `http`ï¼ˆé»˜è®¤ï¼‰æˆ– `stdio` |
| `LLM_API_KEY` | è¿‡æ»¤ç”¨ | ä»»æ„ OpenAI å…¼å®¹çš„ API Key |
| `LLM_BASE_URL` | è¿‡æ»¤ç”¨ | API ç«¯ç‚¹ï¼ˆé»˜è®¤ OpenAIï¼‰|
| `LLM_MODEL` | è¿‡æ»¤ç”¨ | æ¨¡å‹åç§°ï¼ˆé»˜è®¤ gpt-4o-miniï¼‰|

é…ç½®å¥½åé‡å¯ Claude Desktopï¼Œè¯•è¯•ï¼š*"æœç´¢ React useState ç”¨æ³•"*

## å·¥ä½œåŸç†

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä½ çš„ AI    â”‚â”€â”€â”€â”€â–¶â”‚      utcp-mcp-gateway           â”‚â”€â”€â”€â”€â–¶â”‚  ä»»æ„ MCP   â”‚
â”‚ (Claude ç­‰)  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚ (Context7)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  UTCP   â”‚  â”‚ LLM è¿‡æ»¤å™¨  â”‚   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  â”‚  æœç´¢   â”‚  â”‚ 10Kâ†’300å­—ç¬¦ â”‚   â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gateway å‘ä½ çš„ AI æš´éœ² 4 ä¸ªå·¥å…·ï¼š**

| å·¥å…· | å‚æ•° | ä½œç”¨ |
|------|------|------|
| `search_tools` | `query`, `limit` | æŒ‰å…³é”®è¯æœç´¢å·¥å…·ï¼Œåªè¿”å›ç›¸å…³çš„ï¼Œä¸ç”¨åŠ è½½ 500+ å®šä¹‰ |
| `list_tools` | - | åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…· |
| `call_tool` | `tool_name`, `arguments` | è°ƒç”¨ä»»æ„å·¥å…·ï¼Œå“åº”ç» LLM è¿‡æ»¤ï¼ˆç¼©å° 97%ï¼ï¼‰|
| `call_tool_chain` | `code` | æ‰§è¡Œ TypeScript ä»£ç ï¼Œä¸€æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…· |

### è°ƒç”¨æµç¨‹ç¤ºä¾‹

```
ç”¨æˆ·: "React useState æ€ä¹ˆç”¨ï¼Ÿ"

1. AI è°ƒç”¨ search_tools("react")        â†’ è¿”å› 2 ä¸ªç›¸å…³å·¥å…·
2. AI è°ƒç”¨ call_tool("get-library-docs", {topic: "useState"})
3. Gateway ä» Context7 è·å– 10,000 å­—ç¬¦
4. LLM è¿‡æ»¤å™¨æ‘˜è¦ä¸º 300 å­—ç¬¦           â†’ èŠ‚çœ 97% Tokenï¼
5. AI æ”¶åˆ°ç®€æ´ç­”æ¡ˆ
```

## æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ | è¯´æ˜ |
|------|------|
| ğŸ”Œ **é€šç”¨ MCP** | è¿æ¥ä»»æ„ HTTP æˆ– stdio MCP |
| ğŸ§  **LLM è¿‡æ»¤** | æ™ºèƒ½æ‘˜è¦ï¼ˆå“åº”ç¼©å° 97%ï¼ï¼‰|
| ğŸ” **æ¸è¿›å¼å‘ç°** | `search_tools` - æŒ‰éœ€æœç´¢ï¼Œæ— éœ€åŠ è½½å…¨éƒ¨ 500 ä¸ªå·¥å…· |
| âš¡ **Code Mode** | ä¸€æ¬¡è°ƒç”¨æ‰§è¡Œ TypeScript ä»£ç é“¾ |
| ğŸ”’ **å®‰å…¨æ²™ç®±** | ä»£ç åœ¨éš”ç¦»ç¯å¢ƒè¿è¡Œ |
| ğŸ“¦ **é›¶é…ç½®** | åªéœ€ç¯å¢ƒå˜é‡ï¼Œæ— éœ€é…ç½®æ–‡ä»¶ |

## Token èŠ‚çœå®æµ‹

| MCP æœåŠ¡ | åŸå§‹å“åº” | è¿‡æ»¤å | èŠ‚çœ |
|----------|----------|--------|------|
| Context7 | 10,625 å­—ç¬¦ | 326 å­—ç¬¦ | **97%** |
| DeepWiki | 3,318 å­—ç¬¦ | 400 å­—ç¬¦ | **88%** |

## é…ç½®è¯´æ˜

### å•ä¸ª MCP

```bash
MCP_URL=https://mcp.context7.com/mcp
MCP_NAME=context7
```

### å¤šä¸ª MCP

```bash
MCP_URLS=https://mcp.context7.com/mcp,https://mcp.deepwiki.com/mcp
MCP_NAMES=context7,deepwiki
```

### LLM é…ç½®

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `LLM_API_KEY` | - | OpenAI/OpenRouter API å¯†é’¥ |
| `LLM_BASE_URL` | OpenAI | è‡ªå®šä¹‰ç«¯ç‚¹ï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰|
| `LLM_MODEL` | gpt-4o-mini | æ‘˜è¦ç”¨çš„æ¨¡å‹ |
| `ENABLE_LLM_FILTER` | true | å¼€å¯/å…³é—­è¿‡æ»¤ |
| `MAX_RESPONSE_CHARS` | 2000 | æœ€å¤§å“åº”é•¿åº¦ |

---

## Credits / è‡´è°¢

This project is built on top of amazing open-source work:

- **[UTCP (Universal Tool Calling Protocol)](https://github.com/anthropics/utcp)** - The protocol that makes this possible
- **[@utcp/code-mode](https://www.npmjs.com/package/@utcp/code-mode)** - Code execution capabilities
- **[@utcp/sdk](https://www.npmjs.com/package/@utcp/sdk)** - UTCP SDK
- **[@modelcontextprotocol/sdk](https://www.npmjs.com/package/@modelcontextprotocol/sdk)** - MCP SDK by Anthropic

## License

MIT Â© 2025 reinn
